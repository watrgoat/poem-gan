{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape https://www.poetryfoundation.org/poems/browse#page=1&sort_by=recently_added for 40,000 poems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('more_poems.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [[] for _ in range(131)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tags'] = tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16333\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('mostly_english_poems.pickle')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df, df1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('mostly_english_poems.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Poems = df.content.map(lambda x: nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'sees',\n",
       " 'birds',\n",
       " 'overhead',\n",
       " ',',\n",
       " 'eggshells',\n",
       " 'seared',\n",
       " 'to',\n",
       " 'their',\n",
       " 'wire-wrapped',\n",
       " 'claws',\n",
       " '.',\n",
       " 'Their',\n",
       " 'flock',\n",
       " '’',\n",
       " 's',\n",
       " 'light',\n",
       " 'dims',\n",
       " 'when',\n",
       " 'cedar',\n",
       " 'smoke',\n",
       " 'sniffs',\n",
       " 'hunger',\n",
       " 'on',\n",
       " 'text',\n",
       " 'messages',\n",
       " 'flailing',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sage',\n",
       " 'brush',\n",
       " '.',\n",
       " 'He',\n",
       " 'unbraids',\n",
       " 'rain',\n",
       " 'from',\n",
       " 'his',\n",
       " 'hair',\n",
       " ',',\n",
       " 'notices',\n",
       " ':',\n",
       " 'each',\n",
       " 'strand',\n",
       " 'slows',\n",
       " 'to',\n",
       " 'a',\n",
       " 'screech',\n",
       " 'when',\n",
       " 'glimpsed',\n",
       " 'by',\n",
       " 'a',\n",
       " 'steer',\n",
       " 'ducking',\n",
       " 'the',\n",
       " 'lasso',\n",
       " '’',\n",
       " 's',\n",
       " 'widening',\n",
       " 'maw',\n",
       " '.',\n",
       " 'With',\n",
       " 'flames',\n",
       " 'belted',\n",
       " 'to',\n",
       " 'his',\n",
       " 'waist',\n",
       " ',',\n",
       " 'he',\n",
       " 'pins',\n",
       " 'moth',\n",
       " 'wings',\n",
       " 'to',\n",
       " 'each',\n",
       " 'word',\n",
       " 'cresting',\n",
       " '.',\n",
       " 'Eyes',\n",
       " 'shell-white',\n",
       " ',',\n",
       " 'he',\n",
       " 'ignites',\n",
       " 'his',\n",
       " 'gas-soaked',\n",
       " 'shoes—',\n",
       " 'emergency',\n",
       " 'lights',\n",
       " 'flare',\n",
       " 'in',\n",
       " 'every',\n",
       " 'limb',\n",
       " 'of',\n",
       " 'his',\n",
       " 'waking',\n",
       " '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Poems[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiGram(dic, poem):\n",
    "    a = poem\n",
    "    b = poem[1:]\n",
    "    for i in range(len(b)):\n",
    "        if(a[i] in dic):\n",
    "            if(b[i] in dic[a[i]]):\n",
    "                dic[a[i]][b[i]] = dic[a[i]][b[i]]+1\n",
    "            else:\n",
    "                dic[a[i]][b[i]] = 1\n",
    "        else:\n",
    "            dic[a[i]]={b[i]:1}\n",
    "            \n",
    "    return(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicBi = {} # The dictionary for the BiGram model\n",
    "for poem in Poems: #Feed it all the poems\n",
    "    dicBi = BiGram(dicBi, poem) #Build the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next_word(word, dic):\n",
    "    Max = 0\n",
    "    next_word = \"\"\n",
    "    for i,j in list(dic[word].items()):\n",
    "        if(j>Max):\n",
    "            Max = j\n",
    "            next_word = i\n",
    "    return(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_word = \"how\"\n",
    "generate_str = prev_word\n",
    "for i in range(20):\n",
    "    next_word = Next_word(prev_word, dicBi)\n",
    "    prev_word = next_word\n",
    "    generate_str = generate_str+\" \"+ next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how to the world , and the world , and the world , and the world , and the world ,'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NGram(dictionary, poem, nGram):\n",
    "    Number_of_Ngrams = len(poem)-nGram+1\n",
    "\n",
    "    for position in range(Number_of_Ngrams):\n",
    "        words = [] \n",
    "        for nWord in range(nGram):\n",
    "            words = words + [poem[nWord+position]]\n",
    "        temp_dic = dictionary\n",
    "\n",
    "        for nWord in range(nGram):\n",
    "            current_word = words[nWord]\n",
    "            last_word = nWord+1==nGram\n",
    "            if(current_word in temp_dic):\n",
    "                if(last_word):\n",
    "                    temp_dic[current_word] = temp_dic[current_word]+1 #Increase the Ngram Count by 1\n",
    "                else:    \n",
    "                    temp_dic = temp_dic[current_word]\n",
    "            else:\n",
    "                create_dic = 0\n",
    "                if(last_word):\n",
    "                    create_dic = 1\n",
    "                else:\n",
    "                    create_dic = {words[-1]:1}\n",
    "                \n",
    "                for k in range(nGram-2,nWord,-1):\n",
    "                    create_dic = {words[k]:create_dic}\n",
    "                temp_dic[current_word] = create_dic\n",
    "                break\n",
    "    return(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic4 = {}\n",
    "for i in Poems:\n",
    "    dic4 = NGram(dic4, i, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next_word3(word1,word2,word3, dic):\n",
    "    Max = 0\n",
    "    next_word = \"\"\n",
    "    for i,j in list(dic[word1][word2][word3].items()):\n",
    "        if(j>Max):\n",
    "            Max = j\n",
    "            next_word = i\n",
    "    return(next_word)\n",
    "#Next_word3(\"NEWLINE\",\"love\",\"is\",dic4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light dims when cedar smoke sniffs hunger on text messages flailing in the sage brush . He unbraids rain from his hair , and her husband , their daughter had not been there Since the thirteenth century . Details frighten me . As the crow You undergo a beautiful catharsis trapped one night\n"
     ]
    }
   ],
   "source": [
    "prev_word1 = \"light\"\n",
    "prev_word2 = \"dims\"#\"Next_word(prev_word1, dic)\"\n",
    "prev_word3 = \"when\"# Next_word2(prev_word1,prev_word2, dic2)\n",
    "generate_str = prev_word1+\" \"+prev_word2 + \" \" +prev_word3\n",
    "for i in range(50):\n",
    "    next_word = Next_word3(prev_word1, prev_word2,prev_word3, dic4)\n",
    "    prev_word1 = prev_word2\n",
    "    prev_word2 = prev_word3\n",
    "    prev_word3 = next_word\n",
    "    generate_str = generate_str+\" \"+ next_word\n",
    "print(generate_str.replace(\"NEWLINE \",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how should i go about generating new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the devices being used for tensorflow operations\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a940dd860dc355cf12de7c6e789bde0b494d41255d0443cce9e7aeeb3f61f9d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
