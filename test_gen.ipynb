{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape https://www.poetryfoundation.org/poems/browse#page=1&sort_by=recently_added for 40,000 poems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import string\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17369\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('poems.pickle')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16502\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.content[i] == '':\n",
    "        df.drop(index=i, inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('clean_poems.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tags[0] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“I write until my face is erased”</td>\n",
       "      <td>Beatriz Miralles de Imperial</td>\n",
       "      <td>I write until my face is erased\\nonly who I am...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entangled</td>\n",
       "      <td>Sherwin Bitsui</td>\n",
       "      <td>He sees birds overhead,\\neggshells seared\\nto ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From “Postcards”</td>\n",
       "      <td>Bert Meyers</td>\n",
       "      <td>ocean\\n\\nThere it is: an immense, gray, agitat...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First Kiss/Under Capitalism</td>\n",
       "      <td>Omotara James</td>\n",
       "      <td>When I learned I had power to build\\non this m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harold Norse says, “Poetry meant being a sissy...</td>\n",
       "      <td>Tyler Raso</td>\n",
       "      <td>As a poet and a faggot, I\\nhave often been app...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16497</th>\n",
       "      <td>Sylvester’s Dying Bed</td>\n",
       "      <td>Langston Hughes</td>\n",
       "      <td>I woke up this mornin’\\n’Bout half-past three....</td>\n",
       "      <td>[Living, Death, Sorrow &amp; Grieving, Love, Heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>At Melville's Tomb</td>\n",
       "      <td>Hart Crane</td>\n",
       "      <td>Often beneath the wave, wide from this ledge\\n...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>A Woman and Mountains</td>\n",
       "      <td>Helen Hoyt</td>\n",
       "      <td>I am rounded, billowed out, hunched like you;\\...</td>\n",
       "      <td>[Nature, Landscapes &amp; Pastorals, Social Commen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16500</th>\n",
       "      <td>Purple</td>\n",
       "      <td>Margaret Steele Anderson</td>\n",
       "      <td>A pigeon walking dainty in the street;\\nThe mo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16501</th>\n",
       "      <td>At Winter Solstice, Iowa City</td>\n",
       "      <td>Stephen Kuusisto</td>\n",
       "      <td>I listen for the footsteps\\nOf my dogs:\\n\\nLit...</td>\n",
       "      <td>[Relationships, Home Life, Arts &amp; Sciences, Po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16502 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                      “I write until my face is erased”   \n",
       "1                                              Entangled   \n",
       "2                                       From “Postcards”   \n",
       "3                            First Kiss/Under Capitalism   \n",
       "4      Harold Norse says, “Poetry meant being a sissy...   \n",
       "...                                                  ...   \n",
       "16497                              Sylvester’s Dying Bed   \n",
       "16498                                 At Melville's Tomb   \n",
       "16499                              A Woman and Mountains   \n",
       "16500                                             Purple   \n",
       "16501                      At Winter Solstice, Iowa City   \n",
       "\n",
       "                             author  \\\n",
       "0      Beatriz Miralles de Imperial   \n",
       "1                    Sherwin Bitsui   \n",
       "2                       Bert Meyers   \n",
       "3                     Omotara James   \n",
       "4                        Tyler Raso   \n",
       "...                             ...   \n",
       "16497               Langston Hughes   \n",
       "16498                    Hart Crane   \n",
       "16499                    Helen Hoyt   \n",
       "16500      Margaret Steele Anderson   \n",
       "16501              Stephen Kuusisto   \n",
       "\n",
       "                                                 content  \\\n",
       "0      I write until my face is erased\\nonly who I am...   \n",
       "1      He sees birds overhead,\\neggshells seared\\nto ...   \n",
       "2      ocean\\n\\nThere it is: an immense, gray, agitat...   \n",
       "3      When I learned I had power to build\\non this m...   \n",
       "4      As a poet and a faggot, I\\nhave often been app...   \n",
       "...                                                  ...   \n",
       "16497  I woke up this mornin’\\n’Bout half-past three....   \n",
       "16498  Often beneath the wave, wide from this ledge\\n...   \n",
       "16499  I am rounded, billowed out, hunched like you;\\...   \n",
       "16500  A pigeon walking dainty in the street;\\nThe mo...   \n",
       "16501  I listen for the footsteps\\nOf my dogs:\\n\\nLit...   \n",
       "\n",
       "                                                    tags  \n",
       "0                                                     []  \n",
       "1                                                     []  \n",
       "2                                                     []  \n",
       "3                                                     []  \n",
       "4                                                     []  \n",
       "...                                                  ...  \n",
       "16497  [Living, Death, Sorrow & Grieving, Love, Heart...  \n",
       "16498                                                 []  \n",
       "16499  [Nature, Landscapes & Pastorals, Social Commen...  \n",
       "16500                                                 []  \n",
       "16501  [Relationships, Home Life, Arts & Sciences, Po...  \n",
       "\n",
       "[16502 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('clean_poems.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if df.tags[i] == []:\n",
    "        df.tags[i] = ''\n",
    "    else:\n",
    "        df.tags[i] = ', '.join(df.tags[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_poems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\olive\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Poems = df.content.map(lambda x: nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'sees',\n",
       " 'birds',\n",
       " 'overhead',\n",
       " ',',\n",
       " 'eggshells',\n",
       " 'seared',\n",
       " 'to',\n",
       " 'their',\n",
       " 'wire-wrapped',\n",
       " 'claws',\n",
       " '.',\n",
       " 'Their',\n",
       " 'flock',\n",
       " '’',\n",
       " 's',\n",
       " 'light',\n",
       " 'dims',\n",
       " 'when',\n",
       " 'cedar',\n",
       " 'smoke',\n",
       " 'sniffs',\n",
       " 'hunger',\n",
       " 'on',\n",
       " 'text',\n",
       " 'messages',\n",
       " 'flailing',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sage',\n",
       " 'brush',\n",
       " '.',\n",
       " 'He',\n",
       " 'unbraids',\n",
       " 'rain',\n",
       " 'from',\n",
       " 'his',\n",
       " 'hair',\n",
       " ',',\n",
       " 'notices',\n",
       " ':',\n",
       " 'each',\n",
       " 'strand',\n",
       " 'slows',\n",
       " 'to',\n",
       " 'a',\n",
       " 'screech',\n",
       " 'when',\n",
       " 'glimpsed',\n",
       " 'by',\n",
       " 'a',\n",
       " 'steer',\n",
       " 'ducking',\n",
       " 'the',\n",
       " 'lasso',\n",
       " '’',\n",
       " 's',\n",
       " 'widening',\n",
       " 'maw',\n",
       " '.',\n",
       " 'With',\n",
       " 'flames',\n",
       " 'belted',\n",
       " 'to',\n",
       " 'his',\n",
       " 'waist',\n",
       " ',',\n",
       " 'he',\n",
       " 'pins',\n",
       " 'moth',\n",
       " 'wings',\n",
       " 'to',\n",
       " 'each',\n",
       " 'word',\n",
       " 'cresting',\n",
       " '.',\n",
       " 'Eyes',\n",
       " 'shell-white',\n",
       " ',',\n",
       " 'he',\n",
       " 'ignites',\n",
       " 'his',\n",
       " 'gas-soaked',\n",
       " 'shoes—',\n",
       " 'emergency',\n",
       " 'lights',\n",
       " 'flare',\n",
       " 'in',\n",
       " 'every',\n",
       " 'limb',\n",
       " 'of',\n",
       " 'his',\n",
       " 'waking',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Poems[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiGram(dic, poem):\n",
    "    a = poem\n",
    "    b = poem[1:]\n",
    "    for i in range(len(b)):\n",
    "        if(a[i] in dic):\n",
    "            if(b[i] in dic[a[i]]):\n",
    "                dic[a[i]][b[i]] = dic[a[i]][b[i]]+1\n",
    "            else:\n",
    "                dic[a[i]][b[i]] = 1\n",
    "        else:\n",
    "            dic[a[i]]={b[i]:1}\n",
    "            \n",
    "    return(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicBi = {} # The dictionary for the BiGram model\n",
    "for poem in Poems: #Feed it all the poems\n",
    "    dicBi = BiGram(dicBi, poem) #Build the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next_word(word, dic):\n",
    "    Max = 0\n",
    "    next_word = \"\"\n",
    "    for i,j in list(dic[word].items()):\n",
    "        if(j>Max):\n",
    "            Max = j\n",
    "            next_word = i\n",
    "    return(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_word = \"huh\"\n",
    "generate_str = prev_word\n",
    "for i in range(20):\n",
    "    next_word = Next_word(prev_word, dicBi)\n",
    "    prev_word = next_word\n",
    "    generate_str = generate_str+\" \"+ next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huh ? I ’ s a man , and the way to the way to the way to the way to'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NGram(dictionary, poem, nGram):\n",
    "    Number_of_Ngrams = len(poem)-nGram+1\n",
    "\n",
    "    for position in range(Number_of_Ngrams):\n",
    "        words = [] \n",
    "        for nWord in range(nGram):\n",
    "            words = words + [poem[nWord+position]]\n",
    "        temp_dic = dictionary\n",
    "\n",
    "        for nWord in range(nGram):\n",
    "            current_word = words[nWord]\n",
    "            last_word = nWord+1==nGram\n",
    "            if(current_word in temp_dic):\n",
    "                if(last_word):\n",
    "                    temp_dic[current_word] = temp_dic[current_word]+1 #Increase the Ngram Count by 1\n",
    "                else:    \n",
    "                    temp_dic = temp_dic[current_word]\n",
    "            else:\n",
    "                create_dic = 0\n",
    "                if(last_word):\n",
    "                    create_dic = 1\n",
    "                else:\n",
    "                    create_dic = {words[-1]:1}\n",
    "                \n",
    "                for k in range(nGram-2,nWord,-1):\n",
    "                    create_dic = {words[k]:create_dic}\n",
    "                temp_dic[current_word] = create_dic\n",
    "                break\n",
    "    return(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic4 = {}\n",
    "for i in Poems:\n",
    "    dic4 = NGram(dic4, i,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next_word3(word1,word2,word3, dic):\n",
    "    Max = 0\n",
    "    next_word = \"\"\n",
    "    for i,j in list(dic[word1][word2][word3].items()):\n",
    "        if(j>Max):\n",
    "            Max = j\n",
    "            next_word = i\n",
    "    return(next_word)\n",
    "#Next_word3(\"NEWLINE\",\"love\",\"is\",dic4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[264], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m generate_str \u001b[39m=\u001b[39m prev_word1\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mprev_word2 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39mprev_word3\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     next_word \u001b[39m=\u001b[39m Next_word3(prev_word1, prev_word2,prev_word3, dic4)\n\u001b[0;32m      7\u001b[0m     prev_word1 \u001b[39m=\u001b[39m prev_word2\n\u001b[0;32m      8\u001b[0m     prev_word2 \u001b[39m=\u001b[39m prev_word3\n",
      "Cell \u001b[1;32mIn[261], line 4\u001b[0m, in \u001b[0;36mNext_word3\u001b[1;34m(word1, word2, word3, dic)\u001b[0m\n\u001b[0;32m      2\u001b[0m Max \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      3\u001b[0m next_word \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m i,j \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(dic[word1][word2][word3]\u001b[39m.\u001b[39mitems()):\n\u001b[0;32m      5\u001b[0m     \u001b[39mif\u001b[39;00m(j\u001b[39m>\u001b[39mMax):\n\u001b[0;32m      6\u001b[0m         Max \u001b[39m=\u001b[39m j\n",
      "\u001b[1;31mKeyError\u001b[0m: 'is'"
     ]
    }
   ],
   "source": [
    "prev_word1 = \"elmer\"\n",
    "prev_word2 = \"is\"#\"Next_word(prev_word1, dic)\"\n",
    "prev_word3 = \"all\"# Next_word2(prev_word1,prev_word2, dic2)\n",
    "generate_str = prev_word1+\" \"+prev_word2 + \" \" +prev_word3\n",
    "for i in range(50):\n",
    "    next_word = Next_word3(prev_word1, prev_word2,prev_word3, dic4)\n",
    "    prev_word1 = prev_word2\n",
    "    prev_word2 = prev_word3\n",
    "    prev_word3 = next_word\n",
    "    generate_str = generate_str+\" \"+ next_word\n",
    "print(generate_str.replace(\"NEWLINE \",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how should i go about generating new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log the devices being used for tensorflow operations\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a940dd860dc355cf12de7c6e789bde0b494d41255d0443cce9e7aeeb3f61f9d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
